\documentclass[10pt, twocolumn]{article}
\usepackage[margin=1in]{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Analyzing Encrypted Web Traffic with Single- and Multi-Class SVMs}
\author{Emily Stark}
\date{\today}                                          % Activate to display a given date or no date

\begin{document}
\maketitle
%\section{}
%\subsection{}

\section{Introduction}
Web users, especially those in regions with censored 
Internet access, often use encryption in conjunction 
with anonymizing proxies to conceal which website 
they are visiting. For example, a user whose government 
restricts access to \texttt{https://www.facebook.com} can choose a 
proxy in an uncensored region, and use that proxy to 
forward encrypted HTTP requests and responses to and 
from Facebook. In theory, the censoring entity cannot determine from 
the user's encrypted traffic that the user is visiting 
Facebook. However, encryption does not conceal the direction, 
size, and timing of the packets that a user's web browsing 
generates. In practice, this small amount of information can 
be enough to determine the website that the user is visiting.

This problem is naturally phrased as a supervised learning 
problem. Given a set of packet traces, where each trace is labelled 
with the website that a user visited to generate it, we would 
like to determine the website that a user visited to generate a new, 
unlabeled trace. The point of training such a classifier is not 
necessarily to make it easier for a censor to do its job, but rather 
to understand the security guarantees that a user gets from using 
an anonymizing proxy to forward encrypted web traffic, as well as 
the effectiveness of proposed defenses against traffic analysis. 
One such proposed defense is to generate a background request to a 
random website for every encrypted request to a sensitive website~\cite{torfingerprinting}. 
This defense, which I will refer to as the random-visit defense, 
purportedly confuses the classifier by the addition of random 
noise to the traffic generated by a visit to a sensitive website.

In this project, I applied support vector machine (SVM) classifiers 
to the problem of determining the source website of a stream of 
encrypted web traffic. My goals were 1.) to train a SVM to 
effectively classify traces of encrypted packets into their source 
websites, and 2.) to show that SVMs can be used to break the random-visit 
defense described above. While SVMs have been used before for 
encrypted traffic analysis~\cite{SOMETHING}, the random-visit defense 
is a very recent proposal and has not been well-studied yet.

Previous work classifies encrypted traffic analysis into two settings: 
closed world and open world. In the closed world setting, we assume that 
the user visits one of a small number of websites over an encrypted, 
anonymized connection, and the censor wishes to determine which website 
the user is visiting. In the open world problem, which is much harder, the 
censor has a small list of offensive websites that it wishes to block, but 
the user might visit any website on the Internet. The censor wishes to 
recognize when the user is visiting one of the offensive websites, and which 
of the offensive websites is being visited. I used SVM-based techniques to 
perform traffic analysis in both settings.

Below I summarize the tasks that I completed for this project.
\begin{itemize}
\item \textbf{Data generation and preprocessing.} I generated packet 
traces of visits to HTTPS websites, both with and without random 
background visits. From these traces, I generated a feature vector for 
each visit. This process is described in more detail in Section~\ref{sec:data}. 
\item \textbf{Training binary and multiclass SVMs.} I used the 
generated data to train several types of SVMs from the Python scikits-learn 
library~\cite{sklearn}. These included a binary SVM, as well as one-vs-all
and one-vs-one multiclass SVMs based on a binary SVM. I used $k$-fold cross-validation 
to determine the SVM parameters.
\item \textbf{Implementing a multiclass SVM and a single-class SVM for anomaly detection.} 
I built a multiclass SVM using the Python \texttt{cvxopt} library~\cite{cvxopt}, 
trained it, and measured the classification accuracy. To investigate the 
open-world setting, I also built and trained a single-class SVM to perform 
anomaly detection.
\end{itemize}

All the code that I wrote for this project is available online~\cite{github}.

\section{Related Work}

Much previous work has analyzed encrypted traffic to reveal the destination website or 
even uncover sensitive information entered by the user on a HTTPS website. Early
approaches simply fingerprinted websites by recording the sizes of objects generated 
by a visit to the website~\cite{safeweb}. Since then, various machine learning 
and data mining techniques, such as Jaccard coefficients and multinomial naive Bayes classifiers,
have been applied to the encrypted traffic analysis problem~\cite{herrmann,liberatore}. 
A recent work showed that SVMs are an effective traffic analysis technique~\cite{tor}, even 
against protocols such as Tor (an anonymity network) that employ pipelining, which makes 
traffic analysis more difficult. This work proposed the random-visit defense discussed above. In 
this project I investigated the effectiveness of the random-visit defense in analyzing 
SSL-encrypted web traffic.

\end{document}  